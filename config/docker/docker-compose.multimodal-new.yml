version: '3.8'

services:
  # LocalAI for general LLM, image, and audio generation
  localai:
    image: quay.io/go-skynet/local-ai:latest
    ports:
      - "8090:8080"
    volumes:
      - ./localai_models:/models
      - ./localai_data:/tmp/localai/
      - ./pareng_boyong_deliverables:/output
    environment:
      - DEBUG=true
      - MODELS_PATH=/models
      - THREADS=4
      - CONTEXT_SIZE=2048
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/models"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    command: >
      /usr/bin/local-ai
      --models-path=/models
      --debug=true
      --threads=4
      --f16=true

  # Pollinations.AI for free image generation
  pollinations:
    build:
      context: .
      dockerfile: Dockerfile.pollinations
    ports:
      - "8091:8081"
    volumes:
      - ./pareng_boyong_deliverables/images:/app/output
    environment:
      - PYTHONPATH=/app
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Wan2GP for CPU video generation
  wan2gp:
    build:
      context: .
      dockerfile: Dockerfile.wan2gp
    ports:
      - "8092:8082"
    volumes:
      - ./pareng_boyong_deliverables/videos:/app/output
      - ./wan2gp_models:/app/models
    environment:
      - PYTHONPATH=/app
      - CUDA_VISIBLE_DEVICES=""  # Force CPU-only
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

networks:
  default:
    name: pareng-boyong-multimodal

volumes:
  localai_models:
  localai_data:
  wan2gp_models: